# Robot Workspace

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![codecov](https://codecov.io/gh/dgaida/robot_workspace/branch/master/graph/badge.svg)](https://codecov.io/gh/dgaida/robot_workspace)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Ein Python-Framework, das die LÃ¼cke zwischen Kamerabildern und physikalischer Robotermanipulation schlieÃŸt. Es bietet die wesentlichen Datenstrukturen und Koordinatentransformationen, die benÃ¶tigt werden, um erkannte Objekte von Visionssystemen in ausfÃ¼hrbare Pick-and-Place-Ziele fÃ¼r Roboterarme umzuwandeln. Das Framework kÃ¼mmert sich um Workspace-Kalibrierung, ObjektreprÃ¤sentation mit physikalischen Eigenschaften und rÃ¤umliches Denken â€“ so kÃ¶nnen mit Kameras ausgestattete Roboter verstehen, "wo" sich Objekte befinden und "wie" sie in realen Koordinaten gegriffen werden kÃ¶nnen.

---

## ğŸ¯ Ãœberblick

Das `robot_workspace`-Paket bietet ein vollstÃ¤ndiges Framework zur Verwaltung von Roboter-Workspaces, einschlieÃŸlich:

- **ğŸ¯ Koordinatentransformationen**: Nahtlose Transformation zwischen Kamera- und Welt-Koordinatensystemen
- **ğŸ“¦ ObjektreprÃ¤sentation**: Reichhaltige Objektmodelle mit Position, Dimensionen, Segmentierungsmasken und Orientierung
- **ğŸ—ºï¸ Workspace-Management**: Definieren und Verwalten mehrerer Workspaces mit unterschiedlichen Konfigurationen
- **ğŸ” RÃ¤umliche Abfragen**: Finden von Objekten nach Position, GrÃ¶ÃŸe, NÃ¤he oder benutzerdefinierten Kriterien
- **ğŸ’¾ Serialisierung**: JSON-basierte Serialisierung fÃ¼r Datenpersistenz und Kommunikation
- **ğŸ¤– Roboter-UnterstÃ¼tzung**: Native UnterstÃ¼tzung fÃ¼r Niryo Ned2 und WidowX 250 6DOF Roboter (Echt und Simulation)

---

## âœ¨ Hauptmerkmale

### Vision & Erkennung
- Integration der Objekterkennung mit Bounding Boxes, Segmentierungsmasken und physikalischen Eigenschaften
- Berechnung des Massenschwerpunkts und optimaler Greiferorientierungen
- UnterstÃ¼tzung fÃ¼r Multi-Objekt-Tracking und Management

### Koordinatensysteme
- Transformation zwischen relativen Bildkoordinaten (0-1) und Weltkoordinaten (Meter)
- Handhabung mehrerer Workspace-Konfigurationen mit unterschiedlichen Kameraposen
- Automatische Erkennung von Workspace-Grenzen

### RÃ¤umliches Denken
- Abfrage von Objekten nach rÃ¤umlichen Beziehungen (links/rechts/oberhalb/unterhalb/nah bei)
- Finden des nÃ¤chstgelegenen Objekts zu angegebenen Koordinaten
- Filtern nach GrÃ¶ÃŸe, Label oder benutzerdefinierten Kriterien

---


## ğŸ“¦ Installation

```bash
pip install -e .
```

FÃ¼r alle Features:
```bash
pip install -e ".[all]"
```

---

## ğŸš€ Schnellstart

```python
from robot_workspace import PoseObjectPNP, Object, Objects, NiryoWorkspaces

# 1. Arbeiten mit Poses
pose = PoseObjectPNP(x=0.2, y=0.1, z=0.05, roll=0.0, pitch=1.57, yaw=0.0)

# 2. ObjektreprÃ¤sentation
obj = Object(
    label="pencil",
    u_min=100, v_min=100, u_max=200, v_max=200,
    mask_8u=None,
    workspace=workspace
)

# 3. RÃ¤umliche Abfragen
objects = Objects([obj1, obj2, obj3])
nearest, distance = objects.get_nearest_detected_object([0.25, 0.05])
```
